[["index.html", "Machine Learning Algorithms 1 Random Forest 1.1 plot 1.2 Margin 1.3 validation set", " Machine Learning Algorithms Katherine Wilson 2022-01-25 1 Random Forest Bootstrap Aggregation used on the training set, to create many, uncorrelated trees. Sample with replacement size N from the set, and each tree is a random sample. Or, you can do feature randomization. The class with the most votes becomes the prediction. 1.1 plot # install.packages(&quot;randomForest&quot;) library(randomForest) ## randomForest 4.6-14 ## Type rfNews() to see new features/changes/bug fixes. data(iris) iris.rf &lt;- randomForest(iris[,-5], iris[,5],prox = TRUE) iris.p &lt;- classCenter(iris[,-5], iris[,5], iris.rf$prox) plot(iris[,3], iris[,4], pch=21, xlab=names(iris)[3], ylab=names(iris)[4], bg=c(&quot;red&quot;, &quot;blue&quot;, &quot;green&quot;)[as.numeric(factor(iris$Species))], main=&quot;Iris Data with Prototypes&quot;) points(iris.p[,3], iris.p[,4], pch=21, cex=2, bg=c(&quot;red&quot;, &quot;blue&quot;, &quot;green&quot;)) 1.1.1 Data split randomForest package. Does not split by training and testing data. Note: curse of dimensionality: data becomes more sparse as you increase then ubmer of features considered, which might lead to overfitting. Ratio of positives to negatives is important for classification. Also missing values # Set random seed to make results reproducible: set.seed(17) # Calculate the size of each of the data sets: data_set_size &lt;- floor(nrow(iris)/2) # Generate a random sample of &quot;data_set_size&quot; indexes indexes &lt;- sample(1:nrow(iris), size = data_set_size) # Assign the data to the correct sets training &lt;- iris[indexes,] validation1 &lt;- iris[-indexes,] 1.1.2 RF on the training set mtry refers to number of features used in the construction of the tree, they are selected at random . 5/75 were misclassified (6.67%), which is OOB estimates. With more features, use cross validaiton to select important feature selection. data(iris) rf1 &lt;- randomForest(Species ~ ., data = training, ntree=100, mtry = 2, importance = TRUE) print(rf1) ## ## Call: ## randomForest(formula = Species ~ ., data = training, ntree = 100, mtry = 2, importance = TRUE) ## Type of random forest: classification ## Number of trees: 100 ## No. of variables tried at each split: 2 ## ## OOB estimate of error rate: 6.67% ## Confusion matrix: ## setosa versicolor virginica class.error ## setosa 27 0 0 0.00000000 ## versicolor 0 22 2 0.08333333 ## virginica 0 3 21 0.12500000 1.1.3 Variable Importance MeanDecrease Accuracy: estimate of the loss in prediction performane when that particular variable is omitted from training set. MeanDecrease Gini: node impurity. High purity means each node contains only elements of a single class. Decrease in Gini when that feature is omitted-&gt; shows how important that feature is to split the data correctly. Importance constructed by shuffling the variable of interest in the out of sample bag, keeping all other variables the same. The random shuffling means that, on average, shuffled variable has no predictive power. This is a measure of how removing a variable decreases accuracy. Measure the decrease in prediction accuracy on the shuffled data. X is important for predicting Y at over Z value, but not for predicting less than Z value. varImpPlot(rf1) 1.2 Margin Margin = proportion of notes for the correct class minus max. proportion of votes for other classes. 1 means that, for the sample, all the votes were correct. See, by colors, which observations were off. For one variable, could have a margin of 0.8, meaning that a few were off, compared to 0.2, an observation consistently misclassified. plot(margin(rf1)) 1.3 validation set prediction_for_table &lt;- predict(rf1, validation1[,-5]) table(observed=validation1[,5],predicted = prediction_for_table) ## predicted ## observed setosa versicolor virginica ## setosa 23 0 0 ## versicolor 0 26 0 ## virginica 0 3 23 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
